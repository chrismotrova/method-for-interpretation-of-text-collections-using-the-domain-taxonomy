{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'categories', 'title_tokenized', 'categories_tokenized',\n",
      "       'categories_vectors'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"arxiv_embeddings.csv\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "\n",
    "for a in df['title']:\n",
    "    titles.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from east.asts import base\n",
    "\n",
    "\n",
    "def clear_text(text, lowerize=True):\n",
    "\n",
    "    pat = re.compile(r'[^A-Za-z0-9 \\-\\n\\r.,;!?А-Яа-я]+')\n",
    "    cleared_text = re.sub(pat, ' ', text)\n",
    "\n",
    "    if lowerize:\n",
    "        cleared_text = cleared_text.lower()\n",
    "\n",
    "    tokens = cleared_text.split()\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def make_substrings(tokens, k=4):\n",
    "\n",
    "    for i in range(max(len(tokens) - k + 1, 1)):\n",
    "        yield ' '.join(tokens[i:i + k])\n",
    "\n",
    "\n",
    "def get_relevance_matrix(texts, strings):\n",
    "\n",
    "    matrix = np.empty((0, len(strings)), float)\n",
    "    prepared_text_tokens = [clear_text(t) for t in texts]\n",
    "\n",
    "    prepared_string_tokens = [clear_text(s) for s in strings]\n",
    "    prepared_strings = [' '.join(t) for t in prepared_string_tokens]\n",
    "\n",
    "    for text_tokens in prepared_text_tokens:\n",
    "        ast = base.AST.get_ast(list(make_substrings(text_tokens)))\n",
    "        row = np.array([ast.score(s) for s in prepared_strings])\n",
    "        matrix = np.append(matrix, [row], axis=0)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def save_matrix(matrix):\n",
    "    np.savetxt(\"relevance_matrix.txt\", matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"taxonomy_leaves.txt\") as f:\n",
    "    strings = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_matrix = get_relevance_matrix(titles[:1500], strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_matrix(relevance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def init(c, data_n):\n",
    "    A = np.random.random(size=(c, data_n))\n",
    "    col_sum = np.sum(A, axis=0)\n",
    "    return A/col_sum\n",
    "\n",
    "\n",
    "def stepfcm(data, cntr, U, T, expo, a, b, nc, ni):\n",
    "    mf = np.power(U, expo)\n",
    "    tf = np.power(T, nc)\n",
    "    tfo = np.power((1-T), nc)\n",
    "    cntr = (np.dot(a*mf+b*tf, data).T/np.sum(\n",
    "        a*mf+b*tf, axis=1).T).T\n",
    "    dist = distfcm(cntr, data)\n",
    "    obj_fcn = np.sum(np.sum(np.power(dist, 2)*(a*mf+b*tf), axis=0)) + np.sum(\n",
    "        ni*np.sum(tfo, axis=0))\n",
    "    ni = mf*np.power(dist, 2)/(np.sum(mf, axis=0))\n",
    "    tmp = np.power(dist, (-2/(nc-1)))\n",
    "    U = tmp/(np.sum(tmp, axis=0))\n",
    "    tmpt = np.power((b/ni)*np.power(dist, 2), (1/(nc-1)))\n",
    "    T = 1/(1+tmpt)\n",
    "    return U, T, cntr, obj_fcn, ni\n",
    "\n",
    "\n",
    "def distfcm(cntr, data):\n",
    "    out = np.zeros(shape=(cntr.shape[0], data.shape[0]))\n",
    "    for k in range(cntr.shape[0]):\n",
    "        out[k] = np.sqrt(np.sum((np.power(data-cntr[k], 2)).T, axis=0))\n",
    "    return out\n",
    "\n",
    "\n",
    "def pfcm(data, c, expo=2, max_iter=1000, min_impro=0.005, a=1, b=4, nc=3):\n",
    "    obj_fcn = np.zeros(shape=(max_iter, 1))\n",
    "    ni = np.zeros(shape=(c, data.shape[0]))\n",
    "    U = init(c, data.shape[0])\n",
    "    T = init(c, data.shape[0])\n",
    "    cntr = np.random.uniform(low=np.min(data), high=np.max(data), size=(\n",
    "        c, data.shape[1]))\n",
    "    for i in range(max_iter):\n",
    "        current_cntr = cntr\n",
    "        U, T, cntr, obj_fcn[i], ni = stepfcm(\n",
    "                data, cntr, U, T, expo, a, b, nc, ni)\n",
    "        if i > 1:\n",
    "            if abs(obj_fcn[i] - obj_fcn[i-1]) < min_impro:\n",
    "                break\n",
    "            elif np.max(abs(cntr - current_cntr)) < min_impro:\n",
    "                break\n",
    "    return cntr, U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntr, U = pfcm(relevance_matrix.T, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"clusters.dat\", U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaves: 351\r\n",
      "All positive weights:\r\n",
      "sample complexity and generalization bounds                  0.58095\r\n",
      "unsupervised learning and clustering                         0.57694\r\n",
      "boolean function learning                                    0.57415\r\n",
      "After transformation:\r\n",
      "sample complexity and generalization bounds                  0.58095\r\n",
      "unsupervised learning and clustering                         0.57694\r\n",
      "boolean function learning                                    0.57415\r\n",
      "Setting weights for internal nodes\r\n",
      "Membership in root: 1.00000\r\n",
      "Pruning tree...\r\n",
      "Setting gaps...\r\n",
      "Other parameters setting...\r\n",
      "ParGenFS main steps...\r\n",
      "Done. Saving...\r\n",
      "Table saved in the file: table.csv\r\n",
      "ete representation saved in the file: taxonomy_tree_lifted.ete\r\n",
      "ete representation saved.\r\n",
      "Done.\r\n"
     ]
    }
   ],
   "source": [
    "!python3 pargenfs.py Data_Science_taxonomy.csv taxonomy_leaves.txt clusters.dat 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaves: 351\r\n",
      "All positive weights:\r\n",
      "sample complexity and generalization bounds                  0.58271\r\n",
      "unsupervised learning and clustering                         0.57670\r\n",
      "boolean function learning                                    0.57260\r\n",
      "After transformation:\r\n",
      "sample complexity and generalization bounds                  0.58271\r\n",
      "unsupervised learning and clustering                         0.57670\r\n",
      "boolean function learning                                    0.57260\r\n",
      "Setting weights for internal nodes\r\n",
      "Membership in root: 1.00000\r\n",
      "Pruning tree...\r\n",
      "Setting gaps...\r\n",
      "Other parameters setting...\r\n",
      "ParGenFS main steps...\r\n",
      "Done. Saving...\r\n",
      "Table saved in the file: table.csv\r\n",
      "ete representation saved in the file: taxonomy_tree_lifted.ete\r\n",
      "ete representation saved.\r\n",
      "Done.\r\n"
     ]
    }
   ],
   "source": [
    "!python3 pargenfs.py Data_Science_taxonomy.csv taxonomy_leaves.txt clusters.dat 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaves: 351\r\n",
      "All positive weights:\r\n",
      "boolean function learning                                    0.58172\r\n",
      "unsupervised learning and clustering                         0.57780\r\n",
      "sample complexity and generalization bounds                  0.57249\r\n",
      "After transformation:\r\n",
      "boolean function learning                                    0.58172\r\n",
      "unsupervised learning and clustering                         0.57780\r\n",
      "sample complexity and generalization bounds                  0.57249\r\n",
      "Setting weights for internal nodes\r\n",
      "Membership in root: 1.00000\r\n",
      "Pruning tree...\r\n",
      "Setting gaps...\r\n",
      "Other parameters setting...\r\n",
      "ParGenFS main steps...\r\n",
      "Done. Saving...\r\n",
      "Table saved in the file: table.csv\r\n",
      "ete representation saved in the file: taxonomy_tree_lifted.ete\r\n",
      "ete representation saved.\r\n",
      "Done.\r\n"
     ]
    }
   ],
   "source": [
    "!python3 pargenfs.py Data_Science_taxonomy.csv taxonomy_leaves.txt clusters.dat 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
